{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainable Quantum Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14360/263102087.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomLayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QonvLayer(nn.Module):\n",
    "    def __init__(self, stride=2, device=\"default.qubit\", wires=4, circuit_layers=4, n_rotations=8, out_channels=4, seed=None):\n",
    "        super(QonvLayer, self).__init__()\n",
    "        \n",
    "        # init device\n",
    "        self.wires = wires\n",
    "        self.dev = qml.device(device, wires=self.wires)\n",
    "        \n",
    "        self.stride = stride\n",
    "        self.out_channels = min(out_channels, wires)\n",
    "        \n",
    "        if seed is None:\n",
    "            seed = np.random.randint(low=0, high=10e6)\n",
    "            \n",
    "        print(\"Initializing Circuit with random seed\", seed)\n",
    "        \n",
    "        # random circuits\n",
    "        @qml.qnode(device=self.dev, interface=\"torch\")\n",
    "        def my_circuit(inputs, weights):\n",
    "            n_inputs=4\n",
    "            # Encoding of 4 classical input values\n",
    "            for j in range(n_inputs):\n",
    "                qml.RY(inputs[j], wires=j)\n",
    "            # Random quantum circuit\n",
    "            RandomLayers(weights, wires=list(range(self.wires)), seed=seed)\n",
    "            \n",
    "            # Measurement producing 4 classical output values\n",
    "            return [qml.expval(qml.PauliZ(j)) for j in range(self.out_channels)]\n",
    "        \n",
    "        weight_shapes = {\"weights\": [circuit_layers, n_rotations]}\n",
    "        self.circuit = qml.qnn.TorchLayer(my_circuit, weight_shapes=weight_shapes)\n",
    "        \n",
    "        # Just to demonstrate the circuit\n",
    "        inputs = torch.from_numpy(np.zeros(4))\n",
    "        weights = torch.from_numpy(np.zeros((4,8)))\n",
    "        print(qml.draw_mpl(my_circuit)(inputs, weights))\n",
    "    \n",
    "    \n",
    "    def my_draw(self):\n",
    "        # build circuit by sending dummy data through it\n",
    "        _ = self.circuit(inputs=torch.from_numpy(np.zeros(4)))\n",
    "        print(self.circuit.qnode.draw())\n",
    "        self.circuit.zero_grad()\n",
    "        \n",
    "    \n",
    "    def forward(self, img):\n",
    "        # TODO : add code to print the initial images\n",
    "        # img is a 4-dims tensor, img[number of imgs, height, width, channels]\n",
    "        \n",
    "        bs, h, w, ch = img.size()\n",
    "        if ch > 1:\n",
    "            img = img.mean(axis=-1).reshape(bs, h, w, 1)\n",
    "                        \n",
    "        kernel_size = 2        \n",
    "        h_out = (h-kernel_size) // self.stride + 1\n",
    "        w_out = (w-kernel_size) // self.stride + 1\n",
    "        \n",
    "        out = torch.zeros((bs, h_out, w_out, self.out_channels))\n",
    "        \n",
    "        for b in range(bs):\n",
    "            # Initial first image of a batch\n",
    "            if b == 0:\n",
    "                print(\"Initial image\")\n",
    "                plt.imshow(img[b, :, :, 0])\n",
    "                plt.show()\n",
    "                \n",
    "            for j in range(0, h - kernel_size + 1, self.stride):\n",
    "                for k in range(0, w - kernel_size + 1, self.stride):\n",
    "                    # Process a squared 2x2 region of the image with a quantum circuit\n",
    "                    q_results = self.circuit(\n",
    "                        inputs=torch.Tensor([\n",
    "                            img[b, j, k, 0],\n",
    "                            img[b, j, k + 1, 0],\n",
    "                            img[b, j + 1, k, 0],\n",
    "                            img[b, j + 1, k + 1, 0]\n",
    "                        ])\n",
    "                    )\n",
    "                    for c in range(self.out_channels):\n",
    "                        out[b, j // kernel_size, k // kernel_size, c] = q_results[c]\n",
    "            \n",
    "            # Here we print for one image all convoluted (filtered) images\n",
    "            if b == 0:\n",
    "                print(\"Coresponding convoluted images\")\n",
    "                my_out = out.detach().numpy()\n",
    "                for c in range(self.out_channels):\n",
    "                    plt.imshow(my_out[b, :, :, c])\n",
    "                    plt.show()       \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test QonvLayer\n",
    "qonv = QonvLayer(circuit_layers=1, n_rotations=8, out_channels=4, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    # normalizing the values inside the image\n",
    "    x = np.array(x)\n",
    "    x = x/255.0\n",
    "    return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=50):\n",
    "    print(\"Starting Training for {} epochs\".format(epochs))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = np.array([])\n",
    "    accs = np.array([])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        global_epoch = epoch\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            global_step = i           \n",
    "\n",
    "            # prepare inputs and labels\n",
    "            x = x.view(-1, 28, 28, 1)\n",
    "            y = y.long()\n",
    "\n",
    "            # reset optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # engage\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # error, gradients and optimization\n",
    "            loss = criterion(y_pred, y)  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # output\n",
    "            acc = accuracy_score(y, y_pred.argmax(-1).numpy())\n",
    "            \n",
    "            accs = np.append(accs, acc)\n",
    "            losses = np.append(losses, loss.item())\n",
    "               \n",
    "            print(\"Epoch:\", epoch, \n",
    "                  \"\\tStep:\", i, \n",
    "                  \"\\tAcc:\", round(acc, 3), \n",
    "                  \"\\tLoss:\", round(loss.item(),3),\n",
    "                  \"\\tMean Loss:\", round(float(losses[-30:].mean()), 3),\n",
    "                  \"\\tMean Acc:\", round(float(accs[-30:].mean()), 3)\n",
    "                 )\n",
    "            print(\"---------------------------------------\\n\")\n",
    "            \n",
    "    return model, losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # prepare dataset\n",
    "    train_set = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=4)\n",
    "    \n",
    "    # build the model\n",
    "    model = torch.nn.Sequential(\n",
    "        QonvLayer(stride=2, circuit_layers=2, n_rotations=4, out_channels=4, seed=9321727),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(in_features=14*14*4, out_features=10)\n",
    "    )\n",
    "    \n",
    "    # start training\n",
    "    model, losses, accs = train(model, train_loader, epochs=10)\n",
    "    \n",
    "    # plot losses and accuracies\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 4))\n",
    "    ax1.plot(losses)\n",
    "    ax1.set_title(\"Loss\")\n",
    "    ax1.set_xlabel(\"Steps\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(accs)\n",
    "    ax2.set_title(\"Accuracy\")\n",
    "    ax2.set_xlabel(\"Steps\")\n",
    "    ax2.set_ylabel(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
